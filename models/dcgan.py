# -*- coding: utf-8 -*-
"""gan_0219.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GNcOOI9SyEo17mj8obEpN4crQ9BbSu2-

## Overview

This notebook implements a very basic Generative Adversarial Network (GAN) for generating chair images. We'll use a DCGAN architecture, which is well-suited for image generation tasks, even with limited datasets.
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import torchvision.utils as vutils
from torch.utils.tensorboard import SummaryWriter

import matplotlib.pyplot as plt
import numpy as np
import os
import random
from PIL import Image
from google.colab import drive
from tqdm.notebook import tqdm
from pathlib import Path

# For reproducibility
random.seed(42)
torch.manual_seed(42)
np.random.seed(42)

"""## Setting up Project

We'll create a simple folder structure with Google Drive.
"""

drive.mount('/content/drive')

base_dir = "/content/drive/MyDrive/Colab Notebooks/chairness_project"
data_dir = f"{base_dir}/chair_images"  # Place to upload chair images
models_dir = f"{base_dir}/models"      # For saving model checkpoints
results_dir = f"{base_dir}/results"    # For generated images and plots

# Create directories
for dir_path in [base_dir, data_dir, models_dir, results_dir]:
    os.makedirs(dir_path, exist_ok=True)

print(f"Project directories created at: {base_dir}")
print(f"Upload chair images to: {data_dir}")

"""## Augmenting Data

Let's check if there are images in the data directory.
"""

image_files = list(Path(data_dir).glob("*.jpg")) + list(Path(data_dir).glob("*.png"))

if len(image_files) == 0:
    print("No images found!")
else:
    print(f"Found {len(image_files)} chair images.")

    # Display a few images as a sample
    if len(image_files) > 0:
        plt.figure(figsize=(12, 6))
        for i, img_path in enumerate(image_files[:5]):  # Show first 5 images
            img = Image.open(img_path)
            plt.subplot(1, 5, i+1)
            plt.imshow(np.array(img))
            plt.axis('off')
        plt.tight_layout()
        plt.show()

"""With limited data, augmentation is crucial. We'll create a custom dataset class and apply aggressive augmentation."""

class ChairDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        """
        Custom dataset for chair images
        Args:
            root_dir: Directory with the images
            transform: Optional transforms to apply
        """
        self.root_dir = root_dir
        self.transform = transform
        self.image_paths = []

        # Get all image files
        valid_extensions = {'.jpg', '.jpeg', '.png'}
        for path in Path(root_dir).glob("*"):
            if path.suffix.lower() in valid_extensions:
                self.image_paths.append(str(path))

        print(f"Dataset contains {len(self.image_paths)} images")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image
        except Exception as e:
            print(f"Error loading {img_path}: {e}")
            # Return a black image if there's an error
            return torch.zeros(3, 64, 64)

"""Let's set up our parameters and create the transformations for data augmentation:

"""

# GAN Parameters
params = {
    'batch_size': 16,        # Smaller batch size for limited data
    'image_size': 64,        # 64x64 images
    'nc': 3,                 # RGB channels
    'nz': 100,               # Size of latent vector
    'ngf': 64,               # Generator feature map size
    'ndf': 64,               # Discriminator feature map size
    'num_epochs': 300,       # Training epochs
    'lr': 0.0002,            # Learning rate
    'beta1': 0.5,            # Adam optimizer beta1
    'beta2': 0.999           # Adam optimizer beta2
}

# Aggressive data augmentation to maximize limited data
transforms_train = transforms.Compose([
    # Resize larger for random crop
    transforms.Resize((params['image_size'] + 12, params['image_size'] + 12)),
    # Random crop
    transforms.RandomCrop(params['image_size']),
    # Horizontal flip
    transforms.RandomHorizontalFlip(p=0.5),
    # Color variations
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),
    # Slight rotation
    transforms.RandomRotation(10),
    # Random shifts and scaling
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    # Convert to tensor
    transforms.ToTensor(),
    # Normalize to [-1, 1]
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Create the dataset and dataloader
chair_dataset = ChairDataset(data_dir, transform=transforms_train)
dataloader = DataLoader(chair_dataset, batch_size=params['batch_size'],
                        shuffle=True, num_workers=2, drop_last=True)

"""Let's visualize what our augmented data looks like:"""

# Show augmented data samples
def show_augmented_samples():
    """Display samples from the training set with augmentation applied"""
    # Get a batch of training data
    real_batch = next(iter(dataloader))

    # Create a grid of images
    plt.figure(figsize=(10, 10))
    plt.axis("off")
    plt.imshow(np.transpose(vutils.make_grid(real_batch[:16], padding=2, normalize=True), (1, 2, 0)))
    plt.show()

show_augmented_samples()

"""## Building the GAN

Now let's define our Generator and Discriminator networks:
"""

# Custom weight initialization
def weights_init(m):
    """Initialize network weights for better training"""
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

# Generator Network
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        self.main = nn.Sequential(
            # Input is Z (latent vector), going into a convolution
            nn.ConvTranspose2d(params['nz'], params['ngf'] * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(params['ngf'] * 8),
            nn.ReLU(True),
            # State size: (ngf*8) x 4 x 4
            nn.ConvTranspose2d(params['ngf'] * 8, params['ngf'] * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(params['ngf'] * 4),
            nn.ReLU(True),
            # State size: (ngf*4) x 8 x 8
            nn.ConvTranspose2d(params['ngf'] * 4, params['ngf'] * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(params['ngf'] * 2),
            nn.ReLU(True),
            # State size: (ngf*2) x 16 x 16
            nn.ConvTranspose2d(params['ngf'] * 2, params['ngf'], 4, 2, 1, bias=False),
            nn.BatchNorm2d(params['ngf']),
            nn.ReLU(True),
            # State size: (ngf) x 32 x 32
            nn.ConvTranspose2d(params['ngf'], params['nc'], 4, 2, 1, bias=False),
            nn.Tanh()
            # Output: (nc) x 64 x 64
        )

    def forward(self, input):
        """Forward pass through the generator"""
        input = input.view(input.size(0), params['nz'], 1, 1)  # Reshape input
        return self.main(input)

# Discriminator Network
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        self.main = nn.Sequential(
            # Input: (nc) x 64 x 64
            nn.Conv2d(params['nc'], params['ndf'], 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # State: (ndf) x 32 x 32
            nn.Conv2d(params['ndf'], params['ndf'] * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(params['ndf'] * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # State: (ndf*2) x 16 x 16
            nn.Conv2d(params['ndf'] * 2, params['ndf'] * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(params['ndf'] * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # State: (ndf*4) x 8 x 8
            nn.Conv2d(params['ndf'] * 4, params['ndf'] * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(params['ndf'] * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # State: (ndf*8) x 4 x 4
            nn.Conv2d(params['ndf'] * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        """Forward pass through the discriminator"""
        return self.main(input).view(-1, 1).squeeze(1)

"""Now let's initialize our models and set up optimizers:"""

# Set up device (GPU or CPU)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Create the generator and initialize weights
netG = Generator().to(device)
netG.apply(weights_init)
print(netG)

# Create the discriminator and initialize weights
netD = Discriminator().to(device)
netD.apply(weights_init)
print(netD)

# Setup loss function and optimizers
criterion = nn.BCELoss()

# Use different learning rates for generator and discriminator for stability
optimizerD = optim.Adam(netD.parameters(), lr=params['lr']*0.5, betas=(params['beta1'], params['beta2']))
optimizerG = optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], params['beta2']))

# Create learning rate schedulers for better training stability
schedulerD = torch.optim.lr_scheduler.StepLR(optimizerD, step_size=50, gamma=0.9)
schedulerG = torch.optim.lr_scheduler.StepLR(optimizerG, step_size=50, gamma=0.9)

# Create fixed noise for visualization throughout training
fixed_noise = torch.randn(36, params['nz'], device=device)

# TensorBoard setup for monitoring training
writer = SummaryWriter(f"{base_dir}/runs")

"""## Training Functions

Let's define functions to save samples and model checkpoints:
"""

# Lists to keep track of progress
G_losses = []
D_losses = []
D_real_scores = []
D_fake_scores = []
img_list = []

# Function to save a sample of generated images
def save_samples(epoch):
    """Generate and save sample images"""
    with torch.no_grad():
        fake = netG(fixed_noise).detach().cpu()

    # Create a grid of images
    grid = vutils.make_grid(fake, padding=2, normalize=True)

    # Save to disk
    img_path = os.path.join(results_dir, f'samples_epoch_{epoch}.png')
    torchvision.utils.save_image(grid, img_path)

    # Add to TensorBoard
    writer.add_image(f'Generated Chairs', grid, epoch)

    return grid

# Function to save model checkpoints
def save_checkpoint(epoch):
    """Save model checkpoints"""
    checkpoint = {
        'epoch': epoch,
        'generator': netG.state_dict(),
        'discriminator': netD.state_dict(),
        'optimizerG': optimizerG.state_dict(),
        'optimizerD': optimizerD.state_dict(),
        'schedulerG': schedulerG.state_dict(),
        'schedulerD': schedulerD.state_dict(),
        'G_losses': G_losses,
        'D_losses': D_losses
    }
    torch.save(checkpoint, os.path.join(models_dir, f'chair_gan_epoch_{epoch}.pth'))

"""## Training Loop

Here's our main training loop:
"""

def train_gan():
    """Main GAN training loop"""
    print("Starting Training Loop...")

    # For each epoch
    for epoch in range(params['num_epochs']):
        # Initialize batch statistics
        epoch_d_loss = 0.0
        epoch_g_loss = 0.0
        epoch_d_real = 0.0
        epoch_d_fake = 0.0

        # Progress bar
        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))

        for i, data in progress_bar:
            ############################
            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
            ###########################
            # Train with real batch
            netD.zero_grad()
            real_cpu = data.to(device)
            b_size = real_cpu.size(0)

            # Label smoothing for stability
            real_label = torch.full((b_size,), 0.9, dtype=torch.float, device=device)  # 0.9 instead of 1
            fake_label = torch.full((b_size,), 0.1, dtype=torch.float, device=device)  # 0.1 instead of 0

            # Forward pass real batch through D
            output_real = netD(real_cpu)
            # Calculate loss on real batch
            errD_real = criterion(output_real, real_label)
            # Calculate gradients
            errD_real.backward()
            D_x = output_real.mean().item()

            # Train with fake batch
            # Generate batch of latent vectors
            noise = torch.randn(b_size, params['nz'], device=device)
            # Generate fake image batch
            fake = netG(noise)
            # Classify fake batch with D
            output_fake = netD(fake.detach())
            # Calculate D's loss on fake batch
            errD_fake = criterion(output_fake, fake_label)
            # Calculate gradients
            errD_fake.backward()
            D_G_z1 = output_fake.mean().item()

            # Add the gradients and update D
            errD = errD_real + errD_fake
            optimizerD.step()

            ############################
            # (2) Update G network: maximize log(D(G(z)))
            ###########################
            netG.zero_grad()
            # Since we just updated D, perform another forward pass of fake batch through D
            output = netD(fake)
            # Calculate G's loss
            errG = criterion(output, real_label)
            # Calculate gradients for G
            errG.backward()
            D_G_z2 = output.mean().item()
            # Update G
            optimizerG.step()

            # Update statistics
            epoch_d_loss += errD.item()
            epoch_g_loss += errG.item()
            epoch_d_real += D_x
            epoch_d_fake += D_G_z2

            # Update progress bar
            progress_bar.set_description(
                f"Epoch [{epoch+1}/{params['num_epochs']}] | "
                f"D_loss: {errD.item():.4f} | G_loss: {errG.item():.4f}"
            )

        # End of epoch
        avg_d_loss = epoch_d_loss / len(dataloader)
        avg_g_loss = epoch_g_loss / len(dataloader)
        avg_d_real = epoch_d_real / len(dataloader)
        avg_d_fake = epoch_d_fake / len(dataloader)

        # Log to TensorBoard
        writer.add_scalar('Loss/Discriminator', avg_d_loss, epoch)
        writer.add_scalar('Loss/Generator', avg_g_loss, epoch)
        writer.add_scalar('Score/D_real', avg_d_real, epoch)
        writer.add_scalar('Score/D_fake', avg_d_fake, epoch)

        # Update learning rates
        schedulerD.step()
        schedulerG.step()

        # Save losses for plotting later
        G_losses.append(avg_g_loss)
        D_losses.append(avg_d_loss)
        D_real_scores.append(avg_d_real)
        D_fake_scores.append(avg_d_fake)

        # Generate and save samples
        if (epoch+1) % 5 == 0 or epoch == 0:
            grid = save_samples(epoch)
            img_list.append(grid)

        # Save model checkpoint
        if (epoch+1) % 10 == 0 or epoch == params['num_epochs']-1:
            save_checkpoint(epoch)

        # Print epoch summary
        print(f"Epoch [{epoch+1}/{params['num_epochs']}] "
              f"D_loss: {avg_d_loss:.4f} | G_loss: {avg_g_loss:.4f} | "
              f"D(x): {avg_d_real:.4f} | D(G(z)): {avg_d_fake:.4f}")

    print("Training complete!")
    writer.close()
    return G_losses, D_losses, img_list


G_losses, D_losses, img_list = train_gan()

"""## Visualization and Evaluation

After training, let's visualize the results:
"""

def plot_losses():
    """Plot the training losses"""
    plt.figure(figsize=(10,5))
    plt.title("Generator and Discriminator Loss During Training")
    plt.plot(G_losses, label="Generator")
    plt.plot(D_losses, label="Discriminator")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.savefig(os.path.join(results_dir, 'loss_plot.png'))
    plt.show()

    # Plot the D(x) and D(G(z)) scores
    plt.figure(figsize=(10,5))
    plt.title("Discriminator Scores During Training")
    plt.plot(D_real_scores, label="D(x) - Real")
    plt.plot(D_fake_scores, label="D(G(z)) - Fake")
    plt.xlabel("Epoch")
    plt.ylabel("Score")
    plt.legend()
    plt.savefig(os.path.join(results_dir, 'scores_plot.png'))
    plt.show()

def generate_chairs(num_images=16):
    """Generate a batch of chair images using the trained model"""
    # Set model to evaluation mode
    netG.eval()

    # Generate random noise
    z = torch.randn(num_images, params['nz'], device=device)

    # Generate images
    with torch.no_grad():
        generated_images = netG(z).detach().cpu()

    # Create a grid of images
    grid = vutils.make_grid(generated_images, padding=2, normalize=True)

    # Display the grid
    plt.figure(figsize=(12,12))
    plt.title("Generated Chair Images")
    plt.imshow(np.transpose(grid, (1,2,0)))
    plt.axis('off')
    plt.savefig(os.path.join(results_dir, 'generated_chairs.png'))
    plt.show()

    return generated_images

# After training, run these to see results:
plot_losses()
generate_chairs(16)

"""## Loading a Saved Model"""

def load_model(checkpoint_path):
    """Load a saved model checkpoint"""
    checkpoint = torch.load(checkpoint_path)

    # Initialize models
    netG = Generator().to(device)
    netD = Discriminator().to(device)

    # Load states
    netG.load_state_dict(checkpoint['generator'])
    netD.load_state_dict(checkpoint['discriminator'])

    # Set to eval mode
    netG.eval()
    netD.eval()

    print(f"Loaded model from epoch {checkpoint['epoch']}")

    return netG, netD

# Example usage:
# model_path = os.path.join(models_dir, 'chair_gan_epoch_100.pth')
# netG, netD = load_model(model_path)
# generate_chairs(16)